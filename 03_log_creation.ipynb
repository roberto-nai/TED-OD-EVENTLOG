{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 03_log_creation\n",
    "# Transforms data into an event log\n",
    "# Events\n",
    "# ID_NOTICE_CN -> case-id\n",
    "# DT_DISPATCH (date) -> PUBLICATION\n",
    "# DT_APPLICATIONS (date) -> PARTICIPATION\n",
    "# DT_AWARD (date) -> AWARD\n",
    "# CONTRACT_START (date) -> CONTRACT-START\n",
    "# CONTRACT_COMPLETION (date) -> CONTRACT-END"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Force to reload extrernal modules every new cell execution\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "### IMPORT ###\n",
    "from pathlib import Path\n",
    "import csv\n",
    "from datetime import datetime\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "### LOCAL IMPORT ###\n",
    "from config import config_reader\n",
    "from utilities import read_csv_data, fix_date, json_data_to_list_dict, dic_get_years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "### GLOBALS ###\n",
    "yaml_config = config_reader.config_read_yaml(\"config.yml\", \"config\")\n",
    "# print(yaml_config) # debug\n",
    "data_dir = str(yaml_config[\"DATA_DIR\"])\n",
    "log_dir = str(yaml_config[\"LOG_DIR\"])\n",
    "ted_cfc_file = str(yaml_config[\"TED_CFC_FILE\"]) # input\n",
    "ted_can_file = str(yaml_config[\"TED_CAN_FILE\"]) # input\n",
    "ted_config_file = str(yaml_config[\"TED_CONFIG_FILE\"]) # input: filter configuration\n",
    "dic_types_cfc = dict(yaml_config[\"TED_CFC_TYPES\"]) # input\n",
    "dic_types_can = dict(yaml_config[\"TED_CAN_TYPES\"]) # input\n",
    "list_ted_log_events = list(yaml_config[\"TED_LOG_EVENTS\"]) # input\n",
    "list_ted_log_attributes = list(yaml_config[\"TED_LOG_ATTRIBUTES\"])\n",
    "ted_join_file = str(yaml_config[\"TED_JOIN_FILE\"]) # output\n",
    "log_file = str(yaml_config[\"LOG_FILE\"]) # output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "*** PROGRAM START ***\n",
      "\n",
      "Start process:  2024-05-28 10:38:07\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### MAIN ###\n",
    "print()\n",
    "print(\"*** PROGRAM START ***\")\n",
    "print()\n",
    "\n",
    "start_time = datetime.now().replace(microsecond=0)\n",
    "print(\"Start process: \", str(start_time))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Filters configuration\n",
      "Configuration file: ted_config.json\n",
      "Configuration list: [{'CAE_TYPE': ['3']}, {'ISO_COUNTRY_CODE': ['IT', 'FR', 'ES', 'DE']}, {'YEAR': [2016, 2017, 2018, 2019, 2020, 2021, 2022]}]\n",
      "Minimum value for YEAR: 2016\n",
      "Maximum value for YEAR: 2022\n"
     ]
    }
   ],
   "source": [
    "# Gets filters from JSON configuration\n",
    "print(\">> Filters configuration\")\n",
    "print(\"Configuration file:\", ted_config_file)\n",
    "list_filters = json_data_to_list_dict(ted_config_file)\n",
    "print(\"Configuration list:\", list_filters) \n",
    "# Find the dictionary with the key 'YEAR' and get min/max values\n",
    "min_year, max_year = dic_get_years(list_filters, 'YEAR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Reading CFC and CAN files\n",
      "Reading: data/TED_CFC_2016-2022.csv\n",
      "Dataframe CFC length: 811398\n",
      "Reading: data/TED_CAN_2016-2022.csv\n",
      "Dataframe CAN length: 730216\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Reads CFC and CAN type CVS\n",
    "print(\">> Reading CFC and CAN files\")\n",
    "path_cfc_file = Path(data_dir) / ted_cfc_file.replace(\"YS\", str(min_year)).replace(\"YE\", str(max_year))\n",
    "print(\"Reading:\", str(path_cfc_file))\n",
    "df_cfc = read_csv_data(path_cfc_file, dic_types_cfc, \";\")\n",
    "df_cfc_len = len(df_cfc)\n",
    "print(\"Dataframe CFC length:\", df_cfc_len)\n",
    "path_can_file = Path(data_dir) / ted_can_file.replace(\"YS\", str(min_year)).replace(\"YE\", str(max_year))\n",
    "print(\"Reading:\", str(path_can_file))\n",
    "df_can = read_csv_data(path_can_file, dic_types_can, \";\")\n",
    "df_can_len = len(df_can)\n",
    "print(\"Dataframe CAN length:\", df_can_len)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Joining CFC and CAN dataframes\n",
      "Joint dataframe shape: (8550053, 96)\n",
      "Data saved to: data/TED_CFC_CAN_2016-2022.csv\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Joint the CFC and CAN dataframe\n",
    "# The two datasets are linked by CFC.FUTURE_CAN_ID = CAN.ID_NOTICE_CAN. Note: the CAN of a CFC may be missing, due to the tender (CFC.ID_NOTICE_CN) not having been awarded.\n",
    "print(\">> Joining CFC and CAN dataframes\")\n",
    "\n",
    "path_out = Path(data_dir) / ted_join_file.replace(\"YS\", str(min_year)).replace(\"YE\", str(max_year))\n",
    "\n",
    "if path_out.exists():\n",
    "    print(\"The CFC and CAN merged file already exists:\", path_out)\n",
    "    print(f\"If you wish to recreate it, delete the file '{path_out}'\")\n",
    "else:\n",
    "    # Join and clean\n",
    "    df_join = pd.merge(left = df_cfc, right = df_can, left_on='FUTURE_CAN_ID', right_on='ID_NOTICE_CAN', how = 'inner')\n",
    "\n",
    "    # Drop columns with '_y'\n",
    "    cols_to_drop = [col for col in df_join.columns if col.endswith('_y')]\n",
    "    df_join.drop(columns=cols_to_drop, inplace=True)\n",
    "    # Rename columns with '_x'\n",
    "    rename_dict = {col: col.rstrip('_x') for col in df_join.columns if col.endswith('_x')}\n",
    "    df_join.rename(columns=rename_dict, inplace=True)\n",
    "\n",
    "    # Output and Save\n",
    "    print(\"Joint dataframe shape:\", df_join.shape)\n",
    "    df_join.to_csv(path_out, sep=\";\", index=False, quoting=csv.QUOTE_NONNUMERIC)\n",
    "    print(\"Data saved to:\", str(path_out)) \n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Preparing the output\n",
      "Event log directory: data_log\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Preparing the output\n",
    "print(\">> Preparing the output\")\n",
    "out_dir = Path(log_dir)\n",
    "print(\"Event log directory:\", str(out_dir))\n",
    "out_dir.mkdir(exist_ok=True)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Creating the event log\n",
      "Features used as trace event: ['ID_NOTICE_CN', 'DT_DISPATCH', 'CONTRACT_START', 'CONTRACT_COMPLETION', 'DT_APPLICATIONS', 'DT_AWARD']\n",
      "Features used as trace attribute: ['TYPE_OF_CONTRACT', 'VALUE_EURO', 'B_ELECTRONIC_AUCTION', 'B_FRA_AGREEMENT', 'TAL_LOCATION_NUTS', 'CPV', 'ISO_COUNTRY_CODE']\n",
      "Features (all): ['ID_NOTICE_CN', 'DT_DISPATCH', 'CONTRACT_START', 'CONTRACT_COMPLETION', 'DT_APPLICATIONS', 'DT_AWARD', 'TYPE_OF_CONTRACT', 'VALUE_EURO', 'B_ELECTRONIC_AUCTION', 'B_FRA_AGREEMENT', 'TAL_LOCATION_NUTS', 'CPV', 'ISO_COUNTRY_CODE']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# List of features of interest for the event log\n",
    "print(\">> Creating the event log\")\n",
    "print(\"Features used as trace event:\", list_ted_log_events)\n",
    "print(\"Features used as trace attribute:\", list_ted_log_attributes)\n",
    "list_ted_log_features = list_ted_log_events + list_ted_log_attributes\n",
    "print(\"Features (all):\", list_ted_log_features)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Starting dataframe\n",
      "Columns considered: Index(['ID_NOTICE_CN', 'DT_DISPATCH', 'CONTRACT_START', 'CONTRACT_COMPLETION',\n",
      "       'DT_APPLICATIONS', 'DT_AWARD', 'TYPE_OF_CONTRACT', 'VALUE_EURO',\n",
      "       'B_ELECTRONIC_AUCTION', 'B_FRA_AGREEMENT', 'TAL_LOCATION_NUTS', 'CPV',\n",
      "       'ISO_COUNTRY_CODE'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Select from the full dataframe only the columns in the feature list\n",
    "print(\"> Starting dataframe\")\n",
    "df_ted_log = df_join[list_ted_log_features]\n",
    "print(\"Columns considered:\", df_ted_log.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Checking distinct feature values\n",
      "B_ELECTRONIC_AUCTION: ['N' nan 'Y']\n",
      "B_FRA_AGREEMENT: ['N' 'Y']\n",
      "TYPE_OF_CONTRACT: ['U' 'S' 'W']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Checking distinct feature values\n",
    "print(\"> Checking distinct feature values\")\n",
    "print(\"B_ELECTRONIC_AUCTION:\", df_ted_log[\"B_ELECTRONIC_AUCTION\"].unique())\n",
    "print(\"B_FRA_AGREEMENT:\", df_ted_log[\"B_FRA_AGREEMENT\"].unique())\n",
    "print(\"TYPE_OF_CONTRACT:\", df_ted_log[\"TYPE_OF_CONTRACT\"].unique())\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Creating the event log\n",
      "> Ordering the event log\n",
      "> Saving the event log\n",
      "Saving event log to: data_log/TED_log_2016-2022.csv\n"
     ]
    }
   ],
   "source": [
    "print(\"> Creating the event log\")\n",
    "\n",
    "# Removes rows with ID_NOTICE_CN null \n",
    "df = df_ted_log[df_ted_log['ID_NOTICE_CN'].notna()]\n",
    "\n",
    "# Event log header\n",
    "event_log = pd.DataFrame(columns=['case_id', 'event', 'timestamp', 't_type', 'amount', 'electronic', 'framework_agr', 'nuts', 'country', 'cpv_division', 'cpv'], dtype=object) # All columns have the default type 'object'.\n",
    "event_log['amount'] = event_log['amount'].astype(float)\n",
    "\n",
    "# print(\"Event log header:\", event_log.columns) # debug\n",
    "\n",
    "# Events (condition T/F, event name, column feature); the column feature contains the timestamp\n",
    "# (ID_NOTICE_CN is the case-id, the other columns contain the timestamp so if they are not empty the event has occurred)\n",
    "conditions = [\n",
    "    (~df['DT_DISPATCH'].isna(), 'PUBLICATION', 'DT_DISPATCH'),\n",
    "    (~df['DT_APPLICATIONS'].isna(), 'PARTICIPATION', 'DT_APPLICATIONS'),\n",
    "    (~df['DT_AWARD'].isna(), 'AWARD', 'DT_AWARD'),\n",
    "    (~df['CONTRACT_START'].isna(), 'CONTRACT-START', 'CONTRACT_START'),\n",
    "    (~df['CONTRACT_COMPLETION'].isna(), 'CONTRACT-END', 'CONTRACT_COMPLETION'),\n",
    "]\n",
    "\n",
    "for condition, event_name, date_col in conditions:\n",
    "    temp_df = df[condition].copy()  # .copy() to avoid SettingWithCopyWarning\n",
    "    temp_df['event'] = event_name\n",
    "    temp_df['timestamp'] = temp_df[date_col].apply(fix_date)\n",
    "    temp_df['case_id'] = temp_df['ID_NOTICE_CN']\n",
    "    temp_df['t_type'] = temp_df['TYPE_OF_CONTRACT']\n",
    "    temp_df['amount'] = temp_df['VALUE_EURO'].astype(float)\n",
    "    temp_df['electronic'] = temp_df['B_ELECTRONIC_AUCTION']\n",
    "    temp_df['framework_agr'] = temp_df['B_FRA_AGREEMENT']\n",
    "    temp_df['nuts'] = temp_df['TAL_LOCATION_NUTS']\n",
    "    temp_df['country'] =  temp_df['ISO_COUNTRY_CODE']\n",
    "    temp_df['cpv_division'] = temp_df['CPV'].str[:2]\n",
    "    temp_df['cpv'] = temp_df['CPV']    \n",
    "    \n",
    "    # Let us ensure that all necessary columns are present before concatenating\n",
    "    temp_df = temp_df[['case_id', 'event', 'timestamp', 't_type', 'amount', 'electronic', 'framework_agr', 'nuts', 'country', 'cpv_division', 'cpv']]\n",
    "    event_log = pd.concat([event_log, temp_df])\n",
    "\n",
    "event_log = event_log.drop_duplicates()\n",
    "\n",
    "print(\"> Ordering the event log\")\n",
    "# Order by 'case_id' and 'timestamp'\n",
    "event_log = event_log.sort_values(by=['case_id', 'timestamp'])\n",
    "\n",
    "print(\"> Saving the event log\")\n",
    "log_file = log_file.replace(\"YS\", str(min_year)).replace(\"YE\", str(max_year))\n",
    "path_out = Path(log_dir) / log_file\n",
    "print(\"Saving event log to:\", str(path_out))\n",
    "event_log.to_csv(path_out, index=False, sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Splitting the event log by country\n",
      "Available countries: ['ES', 'DE', 'FR', 'IT']\n",
      "Saving event log of country 'ES' to: data_log/TED_log_2016-2022_ES.csv\n",
      "Saving event log of country 'DE' to: data_log/TED_log_2016-2022_DE.csv\n",
      "Saving event log of country 'FR' to: data_log/TED_log_2016-2022_FR.csv\n",
      "Saving event log of country 'IT' to: data_log/TED_log_2016-2022_IT.csv\n"
     ]
    }
   ],
   "source": [
    "print(\">> Splitting the event log by country\")\n",
    "list_countries = list(event_log[\"country\"].unique()) # get the coutries\n",
    "print(\"Available countries:\",list_countries)\n",
    "for country in list_countries:\n",
    "    df = event_log[event_log[\"country\"]==country]\n",
    "    log_file_name = f\"{log_file.split('.')[0]}_{country}.csv\"\n",
    "    path_out = Path(log_dir) / log_file_name\n",
    "    print(f\"Saving event log of country '{country}' to:\", str(path_out))\n",
    "    df.to_csv(path_out, index=False, sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "End process: 2024-05-28 10:49:18\n",
      "Time to finish: 0:11:11\n",
      "\n",
      "\n",
      "*** PROGRAM END ***\n",
      "\n"
     ]
    }
   ],
   "source": [
    "end_time = datetime.now().replace(microsecond=0)\n",
    "delta_time = end_time - start_time\n",
    "\n",
    "print()\n",
    "print(\"End process:\", end_time)\n",
    "print(\"Time to finish:\", delta_time)\n",
    "print()\n",
    "\n",
    "print()\n",
    "print(\"*** PROGRAM END ***\")\n",
    "print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
